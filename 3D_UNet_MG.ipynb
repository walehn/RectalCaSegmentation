{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitpytorchconda31c7a5eb31904fc0a44985442d0e7944",
   "display_name": "Python 3.8.5 64-bit ('pytorch': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "from random import *\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import time, math\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "\n",
    "import torchio as tio\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, DataLoader, partition_dataset\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceLoss, GeneralizedDiceLoss\n",
    "from monai.metrics import compute_meandice\n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    AsDiscrete, Compose, LoadNiftid, ToTensord, AddChanneld, LabelToContour,\n",
    ")\n",
    "from monai.networks.blocks import Convolution, Upsample\n",
    "from monai.networks.layers.factories import Pool, Act\n",
    "from monai.networks.layers import split_args\n",
    "from monai.utils import set_determinism\n",
    "from monai.optimizers import Novograd\n",
    "\n",
    "print_config()\n",
    "print('TorchIO version:', tio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MONAI_DATA_DIRECTORY\"] = \"./data\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 1, 2, 3'\n",
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(root_dir, \"nifti_data\")\n",
    "train_images = sorted(glob.glob(os.path.join(data_dir, \"image\", \"*.nii.gz\")))\n",
    "train_labels = sorted(glob.glob(os.path.join(data_dir, \"mask\", \"*.nii.gz\")))\n",
    "data_dicts = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(train_images, train_labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### hyperparameter setting\n",
    "set_determinism(seed=0)\n",
    "\n",
    "bs = 64\n",
    "Height = 480\n",
    "Width = 480\n",
    "Depth = 16\n",
    "epoch_num = 500\n",
    "l_rate = 1e-3\n",
    "multi_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### image augmentation transform with monai and torchio API\n",
    "\n",
    "# HistogramStandardization parameter calculation\n",
    "histogram_landmarks_path = 'landmarks.npy'\n",
    "landmarks = tio.HistogramStandardization.train(\n",
    "    train_images,\n",
    "    output_path=histogram_landmarks_path,\n",
    ")\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "print('\\nTrained landmarks:', landmarks)\n",
    "\n",
    "# transform setting\n",
    "train_transforms_monai = [\n",
    "        LoadNiftid(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "]\n",
    "\n",
    "train_transforms_io = [\n",
    "        tio.CropOrPad((Height, Width, Depth),mask_name='label', include=[\"image\", \"label\"]),\n",
    "        tio.HistogramStandardization({'image': landmarks}, include=[\"image\"]),\n",
    "        tio.ZNormalization(masking_method=tio.ZNormalization.mean, include=[\"image\"]),\n",
    "        tio.RandomNoise(p=0.1, include=[\"image\"]),\n",
    "        tio.RandomFlip(axes=(0,), include=[\"image\", \"label\"]),\n",
    "]\n",
    "\n",
    "validation_transforms_monai = [\n",
    "        LoadNiftid(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "]\n",
    "\n",
    "validation_transforms_io = [\n",
    "    tio.CropOrPad((Height, Width, Depth), include=[\"image\", \"label\"], mask_name='label'),\n",
    "    tio.HistogramStandardization({'image': landmarks}, include=[\"image\"]),\n",
    "    tio.ZNormalization(masking_method=tio.ZNormalization.mean, include=[\"image\"]),\n",
    "]\n",
    "\n",
    "# transform composition\n",
    "train_transforms = Compose(train_transforms_monai + train_transforms_io)\n",
    "val_transforms = Compose(validation_transforms_monai + validation_transforms_io )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train dataset using MONAI cachedataset for speed-up \n",
    "\n",
    "train_data, val_data, test_data = partition_dataset(data_dicts, ratios = [0.8, 0.1, 0.1], shuffle = True)\n",
    "\n",
    "train_ds = CacheDataset(data=train_data, transform=train_transforms, cache_rate=1.0, num_workers=8)\n",
    "val_ds = CacheDataset(data=val_data, transform=val_transforms, cache_rate=1.0, num_workers=8)\n",
    "test_ds = CacheDataset(data=test_data, transform=val_transforms, cache_rate=1.0, num_workers=8)\n",
    "\n",
    "print('\\n'+'Training set:', len(train_data), 'subjects')\n",
    "print('Validation set:', len(val_data), 'subjects')\n",
    "print('Validation set:', len(test_data), 'subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataloader\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=8)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(32, 64, 128, 256, 512),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=3,\n",
    "    norm=Norm.BATCH,\n",
    "    dropout=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### training preparation\n",
    "\n",
    "if multi_GPU:\n",
    "    device = torch.device('cuda',0)\n",
    "    model = torch.nn.DataParallel(model,output_device=0) # wrap the model with DataParallel module\n",
    "    model.cuda()\n",
    "else:\n",
    "    device = torch.device('cuda',0)\n",
    "    model.cuda()\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = l_rate, weight_decay = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## train start\n",
    "\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "epoch_time = []\n",
    "total_start = time.time()\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=True, n_classes=2)\n",
    "post_label = AsDiscrete(to_onehot=True, n_classes=2)\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    epoch_start = time.time()\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step_start = time.time()\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = math.ceil(len(train_ds)/train_loader.batch_size)\n",
    "        print(\n",
    "            f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\"\n",
    "            f\" step time: {(time.time() - step_start):.4f} seconds\"\n",
    "            )\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            metric_sum = 0.0\n",
    "            metric_count = 0\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "                roi_size = (Height, Width, Depth)\n",
    "                sw_batch_size = 1\n",
    "                val_outputs = sliding_window_inference(\n",
    "                val_inputs, roi_size, sw_batch_size, model\n",
    "                        )\n",
    "                val_outputs = post_pred(val_outputs)\n",
    "                val_labels = post_label(val_labels)\n",
    "                value = compute_meandice(\n",
    "                    y_pred=val_outputs,\n",
    "                    y=val_labels,\n",
    "                    include_background=False,\n",
    "                )\n",
    "                metric_count += len(value)\n",
    "                metric_sum += value.sum().item()\n",
    "            metric = metric_sum / metric_count\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model.pth\"))\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f} at epoch: {best_metric_epoch}\"\n",
    "            )\n",
    "    print(\n",
    "        f\"time consuming of epoch {epoch + 1} is:\"\n",
    "        f\" {(time.time() - epoch_start):.4f} seconds\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train completed, best_metric: {best_metric:.4f}  at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, test_data in enumerate(test_loader):\n",
    "        roi_size = (Height, Width, Depth)\n",
    "        sw_batch_size = 1\n",
    "        test_image = test_data[\"image\"].to(device)\n",
    "        test_output = sliding_window_inference(\n",
    "                        test_image, roi_size, sw_batch_size, model)\n",
    "        # plot the slice [:, :, rand]\n",
    "        j = randint(0, len(test_image[0,0,0,0,:])-1)\n",
    "        plt.figure(\"check\", (20, 4))\n",
    "\n",
    "        plt.subplot(1, 5, 1)\n",
    "        plt.title(f\"image {i}\")\n",
    "        plt.imshow(test_image.detach().cpu()[0, 0, :, :, j], cmap=\"gray\")\n",
    "\n",
    "        plt.subplot(1, 5, 2)\n",
    "        plt.title(f\"Ground truth mask {i}\")\n",
    "        plt.imshow(test_data[\"label\"][0, 0, :, :, j])\n",
    "\n",
    "        plt.subplot(1, 5, 3)\n",
    "        plt.title(f\"AI predicted mask {i}\")\n",
    "        argmax = AsDiscrete(argmax=True)(test_output)\n",
    "        plt.imshow(argmax.detach().cpu()[0, 0, :, :, j])\n",
    "\n",
    "        plt.subplot(1, 5, 4)\n",
    "        plt.title(f\"contour {i}\")\n",
    "        contour = LabelToContour()(argmax)\n",
    "        plt.imshow(contour.detach().cpu()[0, 0, :, :, j])\n",
    "\n",
    "        plt.subplot(1, 5, 5)\n",
    "        plt.title(f\"overaying contour {i}\")\n",
    "        map_image = test_image.clone().detach()\n",
    "        map_image[contour==1] = map_image.max()\n",
    "        plt.imshow(map_image.detach().cpu()[0, 0, :, :, j], cmap=\"gray\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}